{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16c7b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import mat73\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Input, Flatten, Add, Multiply, Lambda\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from utils.explanations import calculate_robust_astute_sampled\n",
    "import shap\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac00ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explainer(datatype, ball_r, epsilon, prop_points, exponentiate, classifier):\n",
    "    blackbox_path = 'models/' + datatype + '_blackbox.hdf5'\n",
    "    mnist = pickle.load(open('data/mnist_10_10_train.pkl', 'rb'))\n",
    "    data = mnist[1]\n",
    "    labels = mnist[0]\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
    "    x_train = np.array(x_train).reshape(-1, x_train[0].shape[0]*x_train[0].shape[1])\n",
    "    x_val = np.array(x_val).reshape(-1, x_val[0].shape[0]*x_val[0].shape[1])\n",
    "    y_train, y_val = np.array(y_train), np.array(y_val)\n",
    "    y_train_orig, y_val_orig = y_train.copy(), y_val.copy()\n",
    "    y_train, y_val = to_categorical(y_train), to_categorical(y_val)\n",
    "    input_shape = x_train.shape[-1]\n",
    "    \n",
    "    if classifier == '2layer':\n",
    "        activation = 'relu'\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "\n",
    "        preds = Dense(10, activation='softmax', name='dense3',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "    elif classifier == '4layer':\n",
    "        activation = 'relu'\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "        net = Dense(32, activation=activation, name='dense2',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        net = Dense(32, activation=activation, name='dense3',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        net = Dense(32, activation=activation, name='dense4',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        preds = Dense(10, activation='softmax', name='dense5',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox_extra.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "\n",
    "    elif classifier == 'linear':\n",
    "        activation = None\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "\n",
    "        preds = Dense(10, activation='softmax', name='dense3',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox_linear.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "\n",
    "    elif classifier == 'svm':\n",
    "        pred_model = pickle.load(open('models/' + datatype + '_svm.pk', 'rb'))\n",
    "\n",
    "    if classifier == 'svm':\n",
    "#         training_indices = np.random.choice(len(x_train), int(0.001*len(x_train)), replace=False)\n",
    "        explainer = shap.KernelExplainer(pred_model.predict_proba, shap.kmeans(x_train, 100))\n",
    "\n",
    "\n",
    "        explanation = calculate_robust_astute_sampled(data=x_val,\n",
    "                                                   explainer=explainer,\n",
    "                                                   explainer_type='shap',\n",
    "                                                   explanation_type='attribution',\n",
    "                                                   ball_r=ball_r,\n",
    "                                                   epsilon=epsilon,\n",
    "                                                   num_points=int(prop_points * len(x_val)),\n",
    "                                                   exponentiate=exponentiate,\n",
    "                                                   calculate_astuteness=False,\n",
    "                                                   NN=False)\n",
    "    else:\n",
    "        background = x_train[np.random.choice(len(x_train), 100, replace=False)]\n",
    "        explainer = shap.GradientExplainer(bbox_model, background)\n",
    "\n",
    "        explanation = calculate_robust_astute_sampled(data=x_val,\n",
    "                                                      explainer=explainer,\n",
    "                                                      explainer_type='shap',\n",
    "                                                      explanation_type='attribution',\n",
    "                                                      ball_r=ball_r,\n",
    "                                                      epsilon=epsilon,\n",
    "                                                      num_points=int(prop_points * len(x_val)),\n",
    "                                                      exponentiate=exponentiate,\n",
    "                                                      calculate_astuteness=False)\n",
    "\n",
    "    del pred_model\n",
    "    return np.abs(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b76847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d372e0ae8b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                            \u001b[0mprop_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprop_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                            \u001b[0mexponentiate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexponentiate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                            classifier=classifiers[c])\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplanation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0f140c34ad4b>\u001b[0m in \u001b[0;36mshap_explainer\u001b[0;34m(datatype, ball_r, epsilon, prop_points, exponentiate, classifier)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                                       \u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop_points\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                                       \u001b[0mexponentiate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexponentiate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                                       calculate_astuteness=False)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mpred_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/ExplainExplainer_Sampled/ExplainExplainers/MNIST/utils/explanations.py\u001b[0m in \u001b[0;36mcalculate_robust_astute_sampled\u001b[0;34m(data, explainer, explainer_type, explanation_type, num_points, ball_r, epsilon, k, exponentiate, calculate_astuteness, NN, data_explanation)\u001b[0m\n\u001b[1;32m    209\u001b[0m         data_explanation = get_explanation(model=explainer,\n\u001b[1;32m    210\u001b[0m                                            \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplainer_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                                            data=data, k=k, NN=NN, masks=masks)\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalculate_astuteness\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/ExplainExplainer_Sampled/ExplainExplainers/MNIST/utils/explanations.py\u001b[0m in \u001b[0;36mget_explanation\u001b[0;34m(model, model_type, data, k, NN, masks)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'shap'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/old_tf/lib/python3.7/site-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_variances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/old_tf/lib/python3.7/site-packages/shap/explainers/_gradient.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msamples_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0mphis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0mphi_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# estimate variance of means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# TODO: this could be avoided by integrating between endpoints if no local smoothing is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/old_tf/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ball_radius = 2\n",
    "epsilon = 0.05\n",
    "prop_points = 0.05\n",
    "run_times = 5\n",
    "exponentiate = 0\n",
    "classifiers = ['2layer', 'linear', '4layer', 'svm']\n",
    "\n",
    "for datatype in ['mnist']:\n",
    "    for c in range(len(classifiers)):\n",
    "        for i in range(run_times):\n",
    "            fname = 'explained_weights/shap/' + 'shap_' + datatype + '_' + classifiers[c] + '_' + str(i) + '.gz'\n",
    "            explanation = shap_explainer(datatype=datatype,\n",
    "                                           ball_r=ball_radius,\n",
    "                                           epsilon=epsilon,\n",
    "                                           prop_points=prop_points,\n",
    "                                           exponentiate=exponentiate,\n",
    "                                           classifier=classifiers[c])\n",
    "            np.savetxt(X=explanation, fname=fname, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d72ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
