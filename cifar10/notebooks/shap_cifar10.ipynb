{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16c7b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import mat73\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Input, Flatten, Add, Multiply, Lambda\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.explanations import calculate_robust_astute_sampled\n",
    "import shap\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac00ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explainer(datatype, ball_r, epsilon, prop_points, exponentiate, classifier):\n",
    "    blackbox_path = 'models/' + datatype + '_blackbox.hdf5'\n",
    "    cifar = pickle.load(open('data/cifar10_6_6_train.pkl', 'rb'))\n",
    "    data = cifar[1]\n",
    "    labels = cifar[0]\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
    "    x_train, x_val = np.array(x_train), np.array(x_val)\n",
    "    x_train, x_val = x_train.reshape((len(x_train), -1)), x_val.reshape((len(x_val), -1))\n",
    "    y_train_orig, y_val_orig = y_train.copy(), y_val.copy()\n",
    "    y_train, y_val = to_categorical(y_train), to_categorical(y_val)\n",
    "    input_shape = x_train.shape[-1]\n",
    "    \n",
    "    if classifier == '2layer':\n",
    "        activation = 'relu'\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "\n",
    "        preds = Dense(10, activation='softmax', name='dense3',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "    elif classifier == '4layer':\n",
    "        activation = 'relu'\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "        net = Dense(32, activation=activation, name='dense2',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        net = Dense(32, activation=activation, name='dense3',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        net = Dense(32, activation=activation, name='dense4',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        preds = Dense(10, activation='softmax', name='dense5',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox_extra.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "\n",
    "    elif classifier == 'linear':\n",
    "        activation = None\n",
    "\n",
    "        model_input = Input(shape=(input_shape,), dtype='float32')\n",
    "\n",
    "        net = Dense(32, activation=activation, name='dense1',\n",
    "                    kernel_regularizer=regularizers.l2(1e-3))(model_input)\n",
    "\n",
    "        preds = Dense(10, activation='softmax', name='dense3',\n",
    "                      kernel_regularizer=regularizers.l2(1e-3))(net)\n",
    "        bbox_model = Model(model_input, preds)\n",
    "        bbox_model.load_weights('models/' + datatype + '_blackbox_linear.hdf5',\n",
    "                                by_name=True)\n",
    "        pred_model = Model(model_input, preds)\n",
    "\n",
    "\n",
    "    elif classifier == 'svm':\n",
    "        pred_model = pickle.load(open('models/' + datatype + '_svm.pk', 'rb'))\n",
    "\n",
    "    if classifier == 'svm':\n",
    "#         training_indices = np.random.choice(len(x_train), int(0.001*len(x_train)), replace=False)\n",
    "        explainer = shap.KernelExplainer(pred_model.predict_proba, shap.kmeans(x_train, 100))\n",
    "\n",
    "\n",
    "        explanation = calculate_robust_astute_sampled(data=x_val,\n",
    "                                                   explainer=explainer,\n",
    "                                                   explainer_type='shap',\n",
    "                                                   explanation_type='attribution',\n",
    "                                                   ball_r=ball_r,\n",
    "                                                   epsilon=epsilon,\n",
    "                                                   num_points=int(prop_points * len(x_val)),\n",
    "                                                   exponentiate=exponentiate,\n",
    "                                                   calculate_astuteness=False,\n",
    "                                                   NN=False)\n",
    "    else:\n",
    "        background = x_train[np.random.choice(len(x_train), 100, replace=False)]\n",
    "        explainer = shap.GradientExplainer(bbox_model, background)\n",
    "\n",
    "        explanation = calculate_robust_astute_sampled(data=x_val,\n",
    "                                                      explainer=explainer,\n",
    "                                                      explainer_type='shap',\n",
    "                                                      explanation_type='attribution',\n",
    "                                                      ball_r=ball_r,\n",
    "                                                      epsilon=epsilon,\n",
    "                                                      num_points=int(prop_points * len(x_val)),\n",
    "                                                      exponentiate=exponentiate,\n",
    "                                                      calculate_astuteness=False)\n",
    "\n",
    "    del pred_model\n",
    "    return np.abs(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b76847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zulqarnain/anaconda3/envs/old_tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 11:47:34.513317: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-05-18 11:47:34.516385: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2022-05-18 11:47:34.516850: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55978e09b300 executing computations on platform Host. Devices:\n",
      "2022-05-18 11:47:34.516866: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3513e53fa95b477d8856b11377df5621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10e089f99f54fa29c967ffee0e84744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f624a60a66e4426be410a5768ad17e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24520b1e517242a3a61a8ecc4dc3017d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eafc74f009a493db0aefe8838bebb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ball_radius = 2\n",
    "epsilon = 0.05\n",
    "prop_points = 0.05\n",
    "run_times = 5\n",
    "exponentiate = 0\n",
    "classifiers = ['2layer', 'linear', '4layer', 'svm']\n",
    "\n",
    "for datatype in ['cifar1006']:\n",
    "    for c in range(len(classifiers)):\n",
    "        for i in range(run_times):\n",
    "            fname = 'explained_weights/shap/' + 'shap_' + datatype + '_' + classifiers[c] + '_' + str(i) + '.gz'\n",
    "            explanation = shap_explainer(datatype=datatype,\n",
    "                                           ball_r=ball_radius,\n",
    "                                           epsilon=epsilon,\n",
    "                                           prop_points=prop_points,\n",
    "                                           exponentiate=exponentiate,\n",
    "                                           classifier=classifiers[c])\n",
    "            np.savetxt(X=explanation, fname=fname, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d72ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
